# uv run ../launch_utils/launch_sbatch_grid.py spectrum_grouped.yaml --max-concurrent 8
command: "uv run generate_answers.py"

# Sbatch configuration for SLURM job submission
sbatch:
  partition: gpu-a100                   # partition
  account: xlab                         # account
  time: "36:00:00"                      # wall time
  ntasks: 1                             # number of tasks
  mem: 80G                              # memory per node
  gpus-per-task: 1                      # GPUs per task
  cpus-per-task: 4                      # CPUs per task
  chdir: "/gscratch/xlab/tsor13/SimBench_release"  # working directory
  output: "logs/%x-%j.out"              # output file pattern
  job-name: "generate-answers"                   # base job name (will be appended with index)

# uv run generate_answers.py \
#     --input_file data/SimBenchPop.pkl \
#     --output_file results/spectrum-gemma-pop.pkl \
#     --model_name tsor13/spectrum-gemma-3-12b-v0 \
#     --method token_prob

base:                                         # merged into every run
  method: token_prob

runs:                                         # model variants
  - model_name: tsor13/spectrum-gemma-3-12b-v0
    output_file: results/spectrum-gemma-grouped.pkl
  
  - model_name: tsor13/spectrum-Llama-3.1-8B-v0
    output_file: results/spectrum-Llama-3.1-8B-grouped.pkl
  
  - model_name: tsor13/spectrum-Qwen3-14B-v0
    output_file: results/spectrum-Qwen3-14B-grouped.pkl
  
  - model_name: google/gemma-3-12b-pt
    output_file: results/gemma-3-12b-pt-grouped.pkl
  
  - model_name: meta-llama/Llama-3.1-8B
    output_file: results/Llama-3.1-8B-grouped.pkl
  
  - model_name: Qwen/Qwen3-14B-Base
    output_file: results/Qwen3-14B-Base-grouped.pkl
  

datasets:
  - input_file: data/SimBenchGrouped.pkl